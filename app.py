import streamlit as st
import time
import json
import os
import requests
import re  # å¼•å…¥æ­£åˆ™ï¼Œç”¨äºåˆ†è¯

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(
    page_title="ç¥ç æ™ºæ ¸ - æ ¸å¿ƒäº¤ä»˜åº•åº§",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. CSS é­”æ³• (ä¿æŒä¸å˜ï¼Œç”¨äºç¾åŒ–)
# ==========================================
st.markdown("""
<style>
    .stApp { background-color: #f3f7fa; font-family: 'Inter', sans-serif; }
    header[data-testid="stHeader"] { display: none; }
    section[data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #e2e8f0; }

    .custom-header {
        position: fixed; top: 0; left: 0; right: 0; height: 70px;
        background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(12px);
        border-bottom: 1px solid #f1f5f9; z-index: 999;
        display: flex; align-items: center; justify-content: space-between;
        padding: 0 40px; margin-left: 20rem;
    }
    @media (max-width: 992px) { .custom-header { margin-left: 0; } }

    .brand-text { font-size: 11px; font-weight: 900; color: #cbd5e1; text-transform: uppercase; letter-spacing: 0.25em; }
    .page-title { font-size: 14px; font-weight: 800; color: #334155; text-transform: uppercase; margin-left: 15px; padding-left: 15px; border-left: 2px solid #e2e8f0; }

    .user-card { display: flex; align-items: center; gap: 15px; }
    .user-info { text-align: right; line-height: 1.2; }
    .user-name { font-size: 13px; font-weight: 900; color: #0f172a; }
    .user-role { font-size: 10px; font-weight: 700; color: #94a3b8; text-transform: uppercase; }
    .user-avatar { width: 42px; height: 42px; background-color: #2563eb; border-radius: 12px; display: flex; align-items: center; justify-content: center; color: white; }

    .content-card { background: white; border-radius: 24px; padding: 30px; border: 1px solid #f1f5f9; box-shadow: 0 10px 30px rgba(0,0,0,0.02); margin-top: 20px; }
    .stButton button { background-color: #2563eb; color: white; border-radius: 10px; border: none; }
    .stButton button:hover { background-color: #1d4ed8; }
    .block-container { padding-top: 90px; }
</style>
""", unsafe_allow_html=True)


# ==========================================
# 3. åç«¯é€»è¾‘åŒº (å·²ä¿®å¤ RAG å’Œ æ¨¡å‹)
# ==========================================

# åŠ è½½çŸ¥è¯†åº“
@st.cache_data
def load_knowledge_base():
    path = os.path.join("public", "knowledge_index.json")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


knowledge_base = load_knowledge_base()


# âœ¨ ä¿®å¤ 2ï¼šå‡çº§ç‰ˆæ£€ç´¢é€»è¾‘ (å…³é”®è¯åˆ†è¯åŒ¹é…)
def search_knowledge(query, top_k=3):
    if not knowledge_base: return []

    # 1. æŠŠç”¨æˆ·é—®é¢˜åˆ‡æˆè¯ (æ¯”å¦‚ "ç½‘å…³æŠ¥é”™" -> "ç½‘å…³", "æŠ¥é”™")
    # ç®€å•æŒ‰ç©ºæ ¼æˆ–ä¸­æ–‡åˆ†è¯é€»è¾‘ï¼ˆè¿™é‡Œç®€å•å¤„ç†ï¼ŒæŠŠé—®é¢˜æŒ‰å­—æˆ–è€…ç©ºæ ¼åˆ‡åˆ†ï¼‰
    # ä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬ç›´æ¥åˆ¤æ–­ query é‡Œçš„å…³é”®è¯æ˜¯å¦å‡ºç°åœ¨æ–‡æ¡£é‡Œ

    scored_results = []

    for item in knowledge_base:
        content = item["content"]
        score = 0

        # ç®€å•ç®—æ³•ï¼šç”¨æˆ·è¾“å…¥çš„æ¯ä¸ªå­—/è¯ï¼Œå¦‚æœåœ¨æ–‡æ¡£é‡Œå‡ºç°ï¼Œå°±åŠ åˆ†
        # æ¯”å¦‚æœ "ç½‘å…³è¶…æ—¶"ï¼Œæ–‡æ¡£é‡Œæœ‰ "ç½‘å…³" +1åˆ†ï¼Œæœ‰ "è¶…æ—¶" +1åˆ†
        if query in content:
            score += 10  # è¿™ç§æ˜¯å®Œå…¨åŒ¹é…ï¼Œåˆ†æœ€é«˜
        else:
            # ç®€å•çš„å­—é¢é‡å ç‡è®¡ç®—
            for char in query:
                if char in content:
                    score += 0.5

        if score > 1:  # åªæœ‰ä¸€ç‚¹ç›¸å…³æ€§çš„æ‰è¦
            scored_results.append((score, item))

    # æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½æ’åº
    scored_results.sort(key=lambda x: x[0], reverse=True)

    # è¿”å›å‰ K ä¸ª
    return [x[1] for x in scored_results[:top_k]]


# Ollama è°ƒç”¨
def call_ollama_stream(model, messages):
    url = "http://localhost:11434/api/chat"
    payload = {"model": model, "messages": messages, "stream": True}
    try:
        with requests.post(url, json=payload, stream=True) as response:
            if response.status_code == 200:
                for line in response.iter_lines():
                    if line:
                        body = json.loads(line)
                        if "message" in body:
                            yield body["message"]["content"]
            else:
                yield f"âŒ Error: {response.status_code}"
    except:
        yield "âŒ è¯·ç¡®è®¤æœ¬åœ° Ollama å·²è¿è¡Œ `ollama serve`"


# ==========================================
# 4. ä¾§è¾¹æ å¯¼èˆª
# ==========================================
with st.sidebar:
    # âœ¨ ä¿®å¤ 1ï¼šåªåŠ è½½æœ¬åœ°å›¾ç‰‡ï¼Œå¦‚æœä¸å­˜å°±ä»€ä¹ˆéƒ½ä¸æ˜¾ç¤ºï¼Œä¸å†æ˜¾ç¤ºå¥‡æ€ªçš„ URL å›¾ç‰‡
    logo_path = "public/logo.png"
    if os.path.exists(logo_path):
        st.image(logo_path, width=60)
    else:
        # å¦‚æœæ²¡å›¾ï¼Œå°±æ˜¾ç¤ºä¸€ä¸ªæ–‡å­— Logo ä»£æ›¿
        st.markdown("### ğŸš€ ç¥ç æ™ºæ ¸")

    st.caption("æ ¸å¿ƒäº¤ä»˜éƒ¨ Â· æ•ˆèƒ½åº•åº§")
    st.markdown("---")

    nav = st.radio(
        "åŠŸèƒ½å¯¼èˆª",
        ["ğŸ“ ç å“¥å°åŠ©æ‰‹", "ğŸ©º æ™ºèƒ½æ•…éšœè¯Šæ–­", "ğŸ“Š ä¸šåŠ¡å·®å¼‚åˆ†æ", "ğŸ“š çŸ¥è¯†åº“ç®¡ç†"],
        label_visibility="collapsed"
    )

    st.markdown("---")

    # âœ¨ ä¿®å¤ 3ï¼šåœ¨åˆ—è¡¨é‡ŒåŠ ä¸Šä½ çš„ qwen3-vl:8b
    st.markdown("#### âš™ï¸ æ¨¡å‹é…ç½®")
    selected_model = st.selectbox(
        "æ¨ç†å¼•æ“",
        ["qwen3-vl:8b", "deepseek-r1", "llama3", "qwen2.5"],  # <--- è¿™é‡ŒåŠ è¿›å»äº†ï¼
        index=0
    )

    st.info(f"ğŸŸ¢ ç³»ç»Ÿåœ¨çº¿\n\nå·²åŠ è½½ {len(knowledge_base)} ä¸ªçŸ¥è¯†åˆ‡ç‰‡")

# ==========================================
# 5. Header å’Œ ä¸»ç•Œé¢
# ==========================================
page_titles = {"ğŸ“ ç å“¥å°åŠ©æ‰‹": "Newcomer Guide", "ğŸ©º æ™ºèƒ½æ•…éšœè¯Šæ–­": "Fault Diagnosis",
               "ğŸ“Š ä¸šåŠ¡å·®å¼‚åˆ†æ": "Business Analysis", "ğŸ“š çŸ¥è¯†åº“ç®¡ç†": "Knowledge Base"}
current_en_title = page_titles.get(nav, "Dashboard")

# æ¸²æŸ“ Header
header_html = f"""
<div class="custom-header">
    <div style="display:flex; align-items:center;">
        <span class="brand-text">DIGITAL CHINA</span>
        <span class="page-title">{current_en_title}</span>
    </div>
    <div style="display:flex; align-items:center; gap: 20px;">
        <div style="color: #94a3b8; cursor: pointer;">ğŸ””</div>
        <div class="user-card">
            <div class="user-info">
                <div class="user-name">Delivery Admin</div>
                <div class="user-role">ç³»ç»Ÿäº¤ä»˜ä¸“å®¶</div>
            </div>
            <div class="user-avatar">User</div>
        </div>
    </div>
</div>
"""
st.markdown(header_html, unsafe_allow_html=True)

# --- åŠŸèƒ½ 1: ç å“¥å°åŠ©æ‰‹ ---
if nav == "ğŸ“ ç å“¥å°åŠ©æ‰‹":
    st.markdown("### ğŸ‘‹ æ¬¢è¿å›æ¥ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ")

    chat_container = st.container()
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    with chat_container:
        for msg in st.session_state.chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    if prompt := st.chat_input("æˆ‘æ˜¯æ–°æ¥çš„ï¼Œè¯·é—®æ€ä¹ˆé…ç½®å¼€å‘ç¯å¢ƒï¼Ÿ"):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                # RAG æ£€ç´¢
                docs = search_knowledge(prompt)

                # æ„é€  Promptï¼šå¼ºåˆ¶è¦æ±‚å‚è€ƒæ–‡æ¡£
                if docs:
                    context = "\n".join([f"- {d['content']}" for d in docs])
                    sys_prompt = (
                        f"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„æŠ€æœ¯å¯¼å¸ˆã€‚è¯·åŠ¡å¿…åŸºäºä»¥ä¸‹ã€å‚è€ƒæ–‡æ¡£ã€‘å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n"
                        f"å¦‚æœå‚è€ƒæ–‡æ¡£é‡Œæ²¡æœ‰ç­”æ¡ˆï¼Œè¯·å‘Šè¯‰ç”¨æˆ·æ–‡æ¡£é‡Œæ²¡å†™ï¼Œä¸è¦çç¼–ã€‚\n\n"
                        f"ã€å‚è€ƒæ–‡æ¡£ã€‘ï¼š\n{context}\n\n"
                        f"ç”¨æˆ·é—®é¢˜ï¼š{prompt}"
                    )
                    st.toast(f"å·²æ£€ç´¢åˆ° {len(docs)} æ¡ç›¸å…³æ–‡æ¡£", icon="ğŸ“š")  # æç¤ºä¸€ä¸‹ç”¨æˆ·æ£€ç´¢æˆåŠŸ
                else:
                    sys_prompt = f"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„æŠ€æœ¯å¯¼å¸ˆã€‚ç”¨æˆ·é—®ï¼š{prompt}ã€‚æœ¬åœ°çŸ¥è¯†åº“æ²¡æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œè¯·ç”¨ä½ çš„é€šç”¨çŸ¥è¯†å›ç­”ï¼Œä½†è¦æç¤ºç”¨æˆ·å»æ›´æ–°æ–‡æ¡£ã€‚"

                response_ph = st.empty()
                full_res = ""
                for chunk in call_ollama_stream(selected_model, [{"role": "user", "content": sys_prompt}]):
                    full_res += chunk
                    response_ph.markdown(full_res + "â–Œ")
                response_ph.markdown(full_res)

                if docs:
                    with st.expander("ğŸ“– æŸ¥çœ‹å‚è€ƒçš„çŸ¥è¯†åº“ç‰‡æ®µ"):
                        for d in docs: st.info(d['content'][:200] + "...")

        st.session_state.chat_history.append({"role": "assistant", "content": full_res})

# --- åŠŸèƒ½ 2: æ™ºèƒ½æ•…éšœè¯Šæ–­ ---
elif nav == "ğŸ©º æ™ºèƒ½æ•…éšœè¯Šæ–­":
    st.markdown("### ğŸ©º å…¨é“¾è·¯æ•…éšœæ ¹å› åˆ†æ")
    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        st.markdown('<div class="content-card">', unsafe_allow_html=True)
        st.subheader("ğŸ“¥ ç°åœºæ•°æ®è¾“å…¥")
        tab_in1, tab_in2 = st.tabs(["æµæ°´å·æ‹‰å–", "æ‰‹åŠ¨ç²˜è´´"])

        log_content = ""
        with tab_in1:
            serial = st.text_input("äº¤æ˜“æµæ°´å·", value="SEQ-20260130-001")
            if st.button("ğŸ“¡ è¿æ¥ ESB æ‹‰å–"):
                with st.status("æ­£åœ¨è¿½è¸ªé“¾è·¯..."):
                    time.sleep(1)
                    st.write("âœ… å·²è·å–æ ¸å¿ƒäº¤æ˜“æ—¥å¿—")
                log_content = """[ERROR] 2026-01-30 14:23:01 [Gateway] Connection timed out calling [LoanCore_V2]
Error Code: ESB-TIMEOUT-0092
TraceId: 7f8a9b2c-1d3e"""
                st.session_state.log_cache = log_content

            if "log_cache" in st.session_state:
                log_content = st.session_state.log_cache
                st.code(log_content, language="log")

        with tab_in2:
            log_content = st.text_area("ç²˜è´´æŠ¥é”™å †æ ˆ", height=200)

        analyze_btn = st.button("âš¡ å¼€å§‹æ™ºèƒ½è¯Šæ–­", type="primary", use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div style="background:#0f172a; border-radius:24px; padding:30px; min-height:500px; color:#e2e8f0; font-family:'JetBrains Mono', monospace;">
            <div style="display:flex; justify-content:space-between; margin-bottom:20px; border-bottom:1px solid #334155; padding-bottom:10px;">
                <span>âœ¨ AI DIAGNOSIS REPORT</span>
                <span style="color:#4ade80;">â— ONLINE</span>
            </div>
            <div id="report-area"></div>
        """, unsafe_allow_html=True)

        if analyze_btn and log_content:
            report_ph = st.empty()
            prompt = f"åˆ†ææ­¤æ—¥å¿—ï¼š{log_content}ã€‚è¯·ä»¥Markdownè¡¨æ ¼å½¢å¼è¾“å‡ºï¼šé”™è¯¯ç±»å‹ã€å®šä½ç»„ä»¶ã€æ ¹å› ã€å»ºè®®ã€‚"

            full_text = ""
            for chunk in call_ollama_stream(selected_model, [{"role": "user", "content": prompt}]):
                full_text += chunk
                report_ph.markdown(f"""
                <div style="background:#0f172a; color:#e2e8f0; padding:10px; border-radius:10px;">
                {full_text}
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("ğŸ‘ˆ ç­‰å¾…è¾“å…¥æ•°æ®...")

        st.markdown("</div>", unsafe_allow_html=True)

# --- åŠŸèƒ½ 3: çŸ¥è¯†åº“ç®¡ç† ---
elif nav == "ğŸ“š çŸ¥è¯†åº“ç®¡ç†":
    st.markdown("### ğŸ“š äº¤ä»˜çŸ¥è¯†åº“é€è§†")
    st.metric("å·²å‘é‡åŒ–æ–‡æ¡£", len(knowledge_base))

    st.markdown("#### ğŸ“‚ ç´¢å¼•åˆ‡ç‰‡é¢„è§ˆ")
    for item in knowledge_base[:5]:
        with st.expander(f"ğŸ“„ç‰‡æ®µ ID: {item.get('id', 'N/A')}"):
            st.write(item['content'])