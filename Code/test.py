import streamlit as st
import requests
import json

# ==========================================
# 1. åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(
    page_title="ITS-æ ¸å¿ƒäº¤ä»˜éƒ¨æ™ºèƒ½åº•åº§",
    page_icon="ğŸ¦",
    layout="wide"
)

# âš ï¸ æ³¨æ„ï¼šè¯·ç¡®ä¿ä½ çš„ Ollama é‡ŒçœŸçš„ä¸‹è½½äº†è¿™ä¸ªåå­—çš„æ¨¡å‹ï¼Œæˆ–è€…ä¿®æ”¹ä¸º 'qwen2.5:7b' ç­‰é€šç”¨æ¨¡å‹
MODEL_NAME = "qwen3-vl:235b-cloud"

# åç«¯ API åœ°å€ (Ollama é»˜è®¤åœ°å€)
OLLAMA_API_URL = "http://localhost:11434/api/generate"

# ==========================================
# 2. ä¾§è¾¹æ è®¾è®¡
# ==========================================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2830/2830284.png", width=80)  # æ¢äº†ä¸€ä¸ªæ›´å•†åŠ¡çš„å›¾æ ‡
    st.title("ğŸš€ äº¤ä»˜æ™ºèƒ½åº•åº§")
    st.markdown("---")

    menu = st.radio("åŠŸèƒ½å¯¼èˆª", ["ğŸ” æ•…éšœæ ¹å› è¯Šæ–­", "ğŸ“š ä¸šåŠ¡å·®å¼‚åˆ†æ", "âš™ï¸ ç³»ç»Ÿè®¾ç½®"])

    st.markdown("---")
    st.caption(f"ğŸŸ¢ ç³»ç»ŸçŠ¶æ€ï¼šåœ¨çº¿")
    st.caption(f"ğŸ§  å½“å‰æ¨¡å‹ï¼š`{MODEL_NAME}`")


# ==========================================
# 3. é€šç”¨å‡½æ•°ï¼šè°ƒç”¨ Ollama
# ==========================================
def query_ollama(prompt):
    """å‘é€è¯·æ±‚ç»™åå° Ollama çš„é€šç”¨å‡½æ•°"""
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False
    }
    try:
        response = requests.post(OLLAMA_API_URL, json=payload, timeout=60)
        if response.status_code == 200:
            return response.json().get('response', "æ¨¡å‹è¿”å›æ•°æ®ä¸ºç©º")
        else:
            return f"âŒ è°ƒç”¨å¤±è´¥ (çŠ¶æ€ç  {response.status_code})ï¼šè¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ã€‚"
    except requests.exceptions.ConnectionError:
        return "âŒ è¿æ¥å¤±è´¥ï¼šè¯·ç¡®ä¿æœ¬åœ° Ollama æœåŠ¡å·²å¯åŠ¨ (localhost:11434)ã€‚"
    except Exception as e:
        return f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{str(e)}"


# ==========================================
# 4. ä¸»é¡µé¢é€»è¾‘
# ==========================================
st.title("ğŸ¦ æ ¸å¿ƒäº¤ä»˜éƒ¨ - è·¨ç³»ç»Ÿæ™ºèƒ½ä¸“å®¶")

# â¤â¤â¤ åŠŸèƒ½ 1: æ•…éšœæ ¹å› è¯Šæ–­
if menu == "ğŸ” æ•…éšœæ ¹å› è¯Šæ–­":
    st.header("ğŸ” æ•…éšœæ—¥å¿—æ ¹å› åˆ†æ")
    st.markdown("è¯¥æ¨¡å—ç”¨äºå¿«é€Ÿåˆ†æç”Ÿäº§ç¯å¢ƒæŠ¥é”™æ—¥å¿—ï¼Œå®šä½é—®é¢˜æ ¹å› ã€‚")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.info("ğŸ‘‡ åŸå§‹æ—¥å¿—è¾“å…¥")
        log_input = st.text_area("ç²˜è´´æŠ¥é”™ä¿¡æ¯", height=350,
                                 placeholder="ä¾‹å¦‚ï¼š\n[ERROR] 2024-01-18 Transaction failed: Connection reset by peer...")
        analyze_btn = st.button("ğŸš€ å¼€å§‹ AI è¯Šæ–­", type="primary", use_container_width=True)

    with col2:
        st.success("ğŸ’¡ AI åˆ†ææŠ¥å‘Š")
        output_container = st.container(border=True)

        if analyze_btn:
            if log_input:
                with output_container:
                    with st.spinner(f"æ­£åœ¨å‘¼å« {MODEL_NAME} åˆ†æå †æ ˆä¿¡æ¯..."):
                        # æ„é€ æç¤ºè¯
                        prompt = f"""
                        ä½ æ˜¯ä¸€ä¸ªé“¶è¡Œæ ¸å¿ƒç³»ç»Ÿèµ„æ·±æ¶æ„å¸ˆã€‚è¯·åˆ†æä»¥ä¸‹æŠ¥é”™æ—¥å¿—ï¼š

                        æ—¥å¿—å†…å®¹ï¼š
                        {log_input}

                        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
                        1. **æ•…éšœæ‘˜è¦**ï¼šç”¨ä¸€å¥è¯æ¦‚æ‹¬é—®é¢˜ã€‚
                        2. **å¯èƒ½æ ¹å› **ï¼šåˆ—å‡º3ä¸ªå¯èƒ½çš„æŠ€æœ¯åŸå› ã€‚
                        3. **æ’æŸ¥å»ºè®®**ï¼šç»™å‡ºå…·ä½“çš„Linuxå‘½ä»¤æˆ–SQLæŸ¥è¯¢å»ºè®®ã€‚
                        4. **è§£å†³æ–¹æ¡ˆ**ï¼šä¿®å¤è¯¥é—®é¢˜çš„æ­¥éª¤ã€‚
                        """
                        result = query_ollama(prompt)
                        st.markdown(result)
            else:
                output_container.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥æ—¥å¿—å†…å®¹ï¼")
        else:
            output_container.info("ç­‰å¾…åˆ†ææŒ‡ä»¤...")

# â¤â¤â¤ åŠŸèƒ½ 2: ä¸šåŠ¡å·®å¼‚åˆ†æ
elif menu == "ğŸ“š ä¸šåŠ¡å·®å¼‚åˆ†æ":
    st.header("ğŸ“š ä¸šåŠ¡è§„åˆ™å·®å¼‚æ¯”å¯¹")
    st.markdown("è¯¥æ¨¡å—ç”¨äºæ¯”å¯¹ **æ–°æ—§ç³»ç»Ÿé€»è¾‘** æˆ– **éœ€æ±‚æ–‡æ¡£ä¸ä»£ç å®ç°** çš„å·®å¼‚ã€‚")

    col_a, col_b = st.columns(2)
    with col_a:
        doc_standard = st.text_area("ğŸ“„ è¾“å…¥æ–‡æ¡£ A (å¦‚ï¼šæ—§ç‰ˆä¸šåŠ¡è§„åˆ™)", height=200)
    with col_b:
        doc_current = st.text_area("ğŸ“„ è¾“å…¥æ–‡æ¡£ B (å¦‚ï¼šæ–°ç‰ˆéœ€æ±‚è¯´æ˜)", height=200)

    compare_btn = st.button("âš–ï¸ å¼€å§‹æ™ºèƒ½æ¯”å¯¹", type="primary")

    if compare_btn:
        if doc_standard and doc_current:
            with st.spinner("æ­£åœ¨è¿›è¡Œè¯­ä¹‰æ¯”å¯¹å’Œå·®å¼‚è¯†åˆ«..."):
                prompt = f"""
                è¯·æ¯”å¯¹ä»¥ä¸‹ä¸¤æ®µä¸šåŠ¡æè¿°çš„å·®å¼‚ã€‚

                ã€æ–‡æ¡£ Aã€‘ï¼š{doc_standard}

                ã€æ–‡æ¡£ Bã€‘ï¼š{doc_current}

                è¯·è¾“å‡ºï¼š
                1. ä¸»è¦å˜æ›´ç‚¹åˆ—è¡¨ã€‚
                2. æ½œåœ¨çš„ä¸šåŠ¡é£é™©æç¤ºã€‚
                3. å¦‚æœæ˜¯é“¶è¡Œè½¬è´¦åœºæ™¯ï¼Œè¯·ç‰¹åˆ«å…³æ³¨é‡‘é¢é™åˆ¶å’Œå®¡æ‰¹æµç¨‹çš„å˜åŒ–ã€‚
                """
                result = query_ollama(prompt)
                st.success("âœ… æ¯”å¯¹å®Œæˆ")
                st.markdown(result)
        else:
            st.warning("âš ï¸ è¯·ç¡®ä¿ä¸¤è¾¹çš„æ–‡æ¡£æ¡†éƒ½å·²å¡«å†™å†…å®¹ã€‚")

# â¤â¤â¤ åŠŸèƒ½ 3: ç³»ç»Ÿè®¾ç½®
elif menu == "âš™ï¸ ç³»ç»Ÿè®¾ç½®":
    st.header("âš™ï¸ ç³»ç»Ÿå‚æ•°è®¾ç½®")
    st.json({
        "System Version": "v1.0.0",
        "Backend Engine": "Ollama Local",
        "Current Model": MODEL_NAME,
        "Max Context Window": "32k",
        "Department": "ITS-Core Delivery"
    })
    st.info("å½“å‰è¿æ¥æ­£å¸¸ï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚")